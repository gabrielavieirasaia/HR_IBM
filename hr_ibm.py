# -*- coding: utf-8 -*-
"""HR_IBM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BjWOWdvcM8oXCCwbcvSkcNYDydEhlGrE

# Importing libraries
"""

!git clone https://github.com/thegiftofgabi/HR_IBM.git

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn

!pip install matplotlib-venn

"""# Uploading Data"""

df = pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition.csv')

"""# Checking Data"""

df.shape

df.dtypes

df.head()

df.info()

df.describe()

"""# Data Visualization"""

df ['Attrition'] = df ['Attrition'].apply(lambda x: 1 if x=='Yes' else 0)
df ['OverTime'] = df ['OverTime'].apply(lambda x: 1 if x=='Yes' else 0)
df ['Over18'] = df ['Over18'].apply(lambda x: 1 if x=='Y' else 0)

df.head()

sns.heatmap(df.isnull(), cbar=False);

df.hist(bins=30, figsize=(20,20));

df = df.drop(['Over18', 'EmployeeCount', 'StandardHours', 'EmployeeNumber'], axis = 1)

left_df = df[df['Attrition'] == 1]
stay_df = df[df['Attrition'] == 0]

print('O número total de funcionários é', len(df))
print('O número de funcionários que deixaram a empresa é', len(left_df))
print('A porcentagem de funcionários que deixaram a empresa é', len(left_df)/len(df)*100)
print('O número de funcionários que ficaram na empresa é', len(stay_df))
print('A porcentagem de funcionários que ficaram na empresa é', len(stay_df)/len(df)*100)

left_df.describe()

stay_df.describe()

correlations = df.corr()
f, ax = plt.subplots(figsize=(20,20))
sns.heatmap(correlations, annot = True);

plt.figure(figsize= [25,12])
sns.countplot (x='Age', hue ='Attrition', data = df);

plt.figure(figsize=[20,20])
plt.subplot(411)
sns.countplot(x='JobRole', hue='Attrition', data = df)
plt.subplot(412)
sns.countplot(x='MaritalStatus', hue='Attrition', data = df)
plt.subplot(413)
sns.countplot(x='JobInvolvement', hue='Attrition', data = df)
plt.subplot(414)
sns.countplot(x='JobLevel', hue='Attrition', data = df)

plt.figure(figsize=(12,7))
sns.kdeplot(left_df['DistanceFromHome'], label='Funcionários que saíram', fill=True);
sns.kdeplot(stay_df['DistanceFromHome'], label='Funcionários que ficaram', color ='r', fill=True);

plt.figure(figsize=(12,7))
sns.kdeplot(left_df['TotalWorkingYears'], label='Funcionários que saíram', fill=True);
sns.kdeplot(stay_df['TotalWorkingYears'], label='Funcionários que ficaram', color ='r', fill=True);

plt.figure(figsize=(15,10))
sns.boxplot(x = 'MonthlyIncome', y= 'Gender', data= df);

plt.figure(figsize=(15,10))
sns.boxplot(x = 'MonthlyIncome', y= 'JobRole', data= df);

"""Pré-Processamento"""

df.head()

X_cat = df[['BusinessTravel','Gender','MaritalStatus', 'JobRole','EducationField','Department']]
X_cat

from sklearn.preprocessing import OneHotEncoder
onehotencoder = OneHotEncoder()
X_cat = onehotencoder.fit_transform(X_cat).toarray()

X_cat.shape

X_cat = pd.DataFrame(X_cat)
type(X_cat)

X_numerical = df[['Age', 'DailyRate', 'DistanceFromHome',	'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement',	'JobLevel',	'JobSatisfaction',	'MonthlyIncome',	'MonthlyRate',	'NumCompaniesWorked',	'OverTime',	'PercentSalaryHike', 'PerformanceRating',	'RelationshipSatisfaction',	'StockOptionLevel',	'TotalWorkingYears'	,'TrainingTimesLastYear'	, 'WorkLifeBalance',	'YearsAtCompany'	,'YearsInCurrentRole', 'YearsSinceLastPromotion',	'YearsWithCurrManager']]

X_all = pd.concat([X_cat, X_numerical], axis = 1)
X_all

X_all.columns = X_all.columns.astype(str)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = scaler.fit_transform(X_all)

X

y = df['Attrition']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

X_train.shape, y_train

X_test.shape, y_test

"""# Regressão logística"""

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression()
logistic.fit(X_train, y_train)

y_pred = logistic.predict(X_test)
y_pred

y_test

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_pred)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)
cm

sns.heatmap(cm, annot=True);

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

precision_score(y_test, y_pred)

recall_score(y_test, y_pred)

f1_score(y_test, y_pred, average='macro')

print(classification_report(y_test, y_pred))

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier

forest = RandomForestClassifier()
forest.fit(X_train, y_train)

y_pred = forest.predict(X_test)

y_pred

accuracy_score(y_test, y_pred)

cm = confusion_matrix(y_pred, y_test)
cm

sns.heatmap(cm, annot=True);

print(classification_report(y_test, y_pred))

"""Redes neurais artificiais"""

import tensorflow as tf